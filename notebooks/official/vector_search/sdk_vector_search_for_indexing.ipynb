{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aharonsh/data-engineering-practice/blob/main/notebooks/official/vector_search/sdk_vector_search_for_indexing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ur8xi4C7S06n"
      },
      "outputs": [],
      "source": [
        "# Copyright 2022 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAPoU8Sm5E6e"
      },
      "source": [
        "# Create Vertex AI Vector Search index\n",
        "\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/vector_search/sdk_vector_search_for_indexing.ipynb\">\n",
        "      <img src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fvertex-ai-samples%2Fmain%2Fnotebooks%2Fofficial%2Fvector_search%2Fsdk_vector_search_for_indexing.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
        "    </a>\n",
        "  </td>    \n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/vector_search/sdk_vector_search_for_indexing.ipynb\">\n",
        "      <img src=\"https://www.gstatic.com/images/branding/gcpiconscolors/vertexai/v1/32px.svg\" alt=\"Vertex AI logo\"><br> Open in Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/vector_search/sdk_vector_search_for_indexing.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.svgrepo.com/download/217753/github.svg\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0a74aaf1481"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This example demonstrates how to use the Vertex AI ANN Service. It's a high scale, low latency solution, to find similar vectors (or more specifically \"embeddings\") for a large corpus. Moreover, it's a fully managed offering, further reducing operational overhead. The Vertex AI ANN Service is built upon [Approximate Nearest Neighbor (ANN) technology](https://ai.googleblog.com/2020/07/announcing-scann-efficient-vector.html) developed by Google Research.\n",
        "\n",
        "Learn more about [Vertex AI Vector Search](https://cloud.google.com/vertex-ai/docs/vector-search/overview)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34a4b245e795"
      },
      "source": [
        "### Objective\n",
        "\n",
        "In this notebook, you learn how to create Approximate Nearest Neighbor (ANN) Index, query against indexes, and validate the performance of the index.\n",
        "\n",
        "This tutorial uses the following Vertex AI services:\n",
        "\n",
        "- Vertex AI Vector Search\n",
        "\n",
        "The steps performed include:\n",
        "\n",
        "* Create ANN Index and Brute Force Index.\n",
        "* Create an IndexEndpoint with VPC Network.\n",
        "* Deploy ANN Index and Brute Force Index.\n",
        "* Perform online query.\n",
        "* Compute recall.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvgnzT1CKxrO"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "The dataset used for this tutorial is the [GloVe dataset](https://nlp.stanford.edu/projects/glove/).\n",
        "\n",
        "GloVe is an unsupervised learning algorithm for obtaining vector representations for words. Training is performed on aggregated global word-word co-occurrence statistics from a corpus. The resulting representations showcase interesting linear substructures of the word vector space.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8925ff9e165e"
      },
      "source": [
        "## Get started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0f1bea346db"
      },
      "source": [
        "### Install Vertex AI SDK for Python and other required packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dfbccc635a17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62a14343-7e4a-41da-b0bc-e26858de0ae0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-aiplatform in /usr/local/lib/python3.12/dist-packages (1.115.0)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Collecting google-cloud-storage\n",
            "  Using cached google_cloud_storage-3.4.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: grpcio-tools in /usr/local/lib/python3.12/dist-packages (1.75.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (3.14.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (2.25.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (6.32.1)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (25.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (3.37.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (1.14.2)\n",
            "Requirement already satisfied: shapely<3.0.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (2.1.1)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (1.34.0)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (2.11.7)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (4.15.0)\n",
            "Requirement already satisfied: docstring_parser<1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-aiplatform) (0.17.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (2.7.2)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (2.32.4)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (1.7.1)\n",
            "Requirement already satisfied: grpcio>=1.75.0 in /usr/local/lib/python3.12/dist-packages (from grpcio-tools) (1.75.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from grpcio-tools) (75.2.0)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.12/dist-packages (from h5py) (2.0.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.70.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform) (1.75.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (4.9.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (2.9.0.post0)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-resource-manager<3.0.0,>=1.3.3->google-cloud-aiplatform) (0.14.2)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform) (4.10.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform) (0.28.1)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform) (8.5.0)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform) (15.0.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->google-cloud-aiplatform) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->google-cloud-aiplatform) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2025.8.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform) (1.3.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# Install the packages\n",
        "! pip3 install --upgrade google-cloud-aiplatform \\\n",
        "                         google-cloud-storage \\\n",
        "                         grpcio-tools \\\n",
        "                         h5py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b08ba354c6e"
      },
      "source": [
        "### Restart runtime (Colab only)\n",
        "\n",
        "To use the newly installed packages, you must restart the runtime on Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bea801acf6b5"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "\n",
        "    import IPython\n",
        "\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b49231643e4"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ The kernel is going to restart. Wait until it's finished before continuing to the next step. ⚠️</b>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7176ea64999b"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "Authenticate your environment on Google Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7de6ef0fac42"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee2dcc922f3d"
      },
      "source": [
        "### Set Google Cloud project information\n",
        "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "80c0215f05a0"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"rons-labs-33840\"  # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4962667eec8e"
      },
      "source": [
        "### Prepare a VPC network\n",
        "To reduce any network overhead that might lead to unnecessary increase in overhead latency, it's best to call the ANN endpoints from your VPC via a direct [VPC Peering](https://cloud.google.com/vertex-ai/docs/general/vpc-peering) connection.\n",
        "  * The following section describes how to setup a VPC Peering connection if you don't have one.\n",
        "  * This is a one-time initial setup task. You can also reuse existing VPC network and skip this section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KDH8CgQiSxhv"
      },
      "outputs": [],
      "source": [
        "VPC_NETWORK = \"colab-research-vpc\"  # @param {type:\"string\"}\n",
        "\n",
        "PEERING_RANGE_NAME = \"ann-haystack-range\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lW2LneA5mmmP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfc10a26-4025-4008-9701-e0c895abd866"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;31mERROR:\u001b[0m (gcloud.compute.networks.create) Could not fetch resource:\n",
            " - The resource 'projects/rons-labs-33840/global/networks/colab-research-vpc' already exists\n",
            "\n",
            "\u001b[1;31mERROR:\u001b[0m (gcloud.compute.firewall-rules.create) Could not fetch resource:\n",
            " - The resource 'projects/rons-labs-33840/global/firewalls/colab-research-vpc-allow-icmp' already exists\n",
            "\n",
            "\u001b[1;31mERROR:\u001b[0m (gcloud.compute.firewall-rules.create) Could not fetch resource:\n",
            " - The resource 'projects/rons-labs-33840/global/firewalls/colab-research-vpc-allow-internal' already exists\n",
            "\n",
            "\u001b[1;31mERROR:\u001b[0m (gcloud.compute.firewall-rules.create) Could not fetch resource:\n",
            " - The resource 'projects/rons-labs-33840/global/firewalls/colab-research-vpc-allow-rdp' already exists\n",
            "\n",
            "\u001b[1;31mERROR:\u001b[0m (gcloud.compute.firewall-rules.create) Could not fetch resource:\n",
            " - The resource 'projects/rons-labs-33840/global/firewalls/colab-research-vpc-allow-ssh' already exists\n",
            "\n",
            "Created [https://www.googleapis.com/compute/v1/projects/rons-labs-33840/global/addresses/ann-haystack-range].\n",
            "Operation \"operations/pssn.p24-249093867948-e7a5ef35-c6b5-4e2f-981f-f5bb85787c7a\" finished successfully.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Remove the if condition to run the encapsulated code\n",
        "if not os.getenv(\"IS_TESTING\"):\n",
        "    # Create a VPC network\n",
        "    ! gcloud compute networks create {VPC_NETWORK} --bgp-routing-mode=regional --subnet-mode=auto --project={PROJECT_ID}\n",
        "\n",
        "    # Add necessary firewall rules\n",
        "    ! gcloud compute firewall-rules create {VPC_NETWORK}-allow-icmp --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow icmp\n",
        "\n",
        "    ! gcloud compute firewall-rules create {VPC_NETWORK}-allow-internal --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow all --source-ranges 10.128.0.0/9\n",
        "\n",
        "    ! gcloud compute firewall-rules create {VPC_NETWORK}-allow-rdp --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow tcp:3389\n",
        "\n",
        "    ! gcloud compute firewall-rules create {VPC_NETWORK}-allow-ssh --network {VPC_NETWORK} --priority 65534 --project {PROJECT_ID} --allow tcp:22\n",
        "\n",
        "    # Reserve IP range\n",
        "    ! gcloud compute addresses create {PEERING_RANGE_NAME} --global --prefix-length=16 --network={VPC_NETWORK} --purpose=VPC_PEERING --project={PROJECT_ID} --description=\"peering range\"\n",
        "\n",
        "    # Set up peering with service networking\n",
        "    # Your account must have the \"Compute Network Admin\" role to run the following.\n",
        "    ! gcloud services vpc-peerings connect --service=servicenetworking.googleapis.com --network={VPC_NETWORK} --ranges={PEERING_RANGE_NAME} --project={PROJECT_ID}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3uj8x73nDX_"
      },
      "source": [
        "* Authentication: Rerun the `gcloud auth login` command in the Vertex AI Workbench notebook terminal when you are logged out and need the credential again."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5de53b31bf1"
      },
      "source": [
        "**WARNING:** The `MatchingIndexEndpoint.match` method (to create online queries against your deployed index) has to be executed in a Vertex AI Workbench notebook instance that is created with the following requirements:\n",
        "  * **In the same region where your ANN service is deployed** (for example, if you set `LOCATION = \"us-central1\"` as same as the tutorial, the notebook instance has to be in `us-central1`).\n",
        "  \n",
        "  * **Make sure you select the VPC network you created for ANN service** (instead of using the \"default\" one). That is, you have to create a new notebook instance that uses the VPC network you created earlier. Run the rest of the tutorial from that notebook instance.\n",
        "  * If you run it in a Colab or a Vertex AI Workbench notebook in a different VPC network or region, \"Create Online Queries\" section is expected to fail."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17ba55acc776"
      },
      "source": [
        "## Import the required libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "56182a4d44c4"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "import h5py\n",
        "from google.cloud import aiplatform\n",
        "from google.cloud.aiplatform.matching_engine.matching_engine_index_endpoint import \\\n",
        "    Namespace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgPO1eR3CYjk"
      },
      "source": [
        "## Create a cloud storage bucket\n",
        "\n",
        "Create a storage bucket to store intermediate artifacts such as datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "MzGDU7TWdts_"
      },
      "outputs": [],
      "source": [
        "BUCKET_URI = f\"gs://your-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EcIXiGsCePi"
      },
      "source": [
        "**If your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NIq7R4HZCfIc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ee944bd-0f0f-4a61-d38d-efd3ed3c2548"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating gs://your-bucket-name-rons-labs-33840-unique/...\n"
          ]
        }
      ],
      "source": [
        "! gsutil mb -l {LOCATION} -p {PROJECT_ID} {BUCKET_URI}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5868f2942b8"
      },
      "source": [
        "## Initialize Vertex AI SDK\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0a2809ebac11"
      },
      "outputs": [],
      "source": [
        "aiplatform.init(project=PROJECT_ID, location=LOCATION, staging_bucket=BUCKET_URI)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lR6Wwv-hCCN-"
      },
      "source": [
        "## Prepare the data\n",
        "\n",
        "The GloVe dataset consists of a set of pre-trained embeddings. The embeddings are split into a \"train\" split, and a \"test\" split. You create a vector search index from the \"train\" split, and use the embedding vectors in the \"test\" split as query vectors to test the vector search index.\n",
        "\n",
        "**Note:** While the data split uses the term \"train\", these are pre-trained embeddings and therefore are ready to be indexed for search. The terms \"train\" and \"test\" split are used just to be consistent with machine learning terminology.\n",
        "\n",
        "Download the GloVe dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9wzS85TeB9dG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68bbe656-5626-4cb6-ca80-41d219364622"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying gs://cloud-samples-data/vertex-ai/matching_engine/glove-100-angular.hdf5...\n",
            "/ [0 files][    0.0 B/462.9 MiB]                                                \r==> NOTE: You are downloading one or more large file(s), which would\n",
            "run significantly faster if you enabled sliced object downloads. This\n",
            "feature is enabled by default but requires that compiled crcmod be\n",
            "installed (see \"gsutil help crcmod\").\n",
            "\n",
            "\\ [1 files][462.9 MiB/462.9 MiB]   30.3 MiB/s                                   \n",
            "Operation completed over 1 objects/462.9 MiB.                                    \n"
          ]
        }
      ],
      "source": [
        "! gsutil cp gs://cloud-samples-data/vertex-ai/matching_engine/glove-100-angular.hdf5 ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fAO9CMoCNtq"
      },
      "source": [
        "Read the data into memory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "lZ3JQTS6CN-3"
      },
      "outputs": [],
      "source": [
        "# The number of nearest neighbors to be retrieved from database for each query.\n",
        "NUM_NEIGHBOURS = 10\n",
        "\n",
        "h5 = h5py.File(\"glove-100-angular.hdf5\", \"r\")\n",
        "train = h5[\"train\"]\n",
        "test = h5[\"test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "pE6bBBo7GjJK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5987abc-3d0e-49da-c276-2d05aef6dbaa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.11333  ,  0.48402  ,  0.090771 , -0.22439  ,  0.034206 ,\n",
              "       -0.55831  ,  0.041849 , -0.53573  ,  0.18809  , -0.58722  ,\n",
              "        0.015313 , -0.014555 ,  0.80842  , -0.038519 ,  0.75348  ,\n",
              "        0.70502  , -0.17863  ,  0.3222   ,  0.67575  ,  0.67198  ,\n",
              "        0.26044  ,  0.4187   , -0.34122  ,  0.2286   , -0.53529  ,\n",
              "        1.2582   , -0.091543 ,  0.19716  , -0.037454 , -0.3336   ,\n",
              "        0.31399  ,  0.36488  ,  0.71263  ,  0.1307   , -0.24654  ,\n",
              "       -0.52445  , -0.036091 ,  0.55068  ,  0.10017  ,  0.48095  ,\n",
              "        0.71104  , -0.053462 ,  0.22325  ,  0.30917  , -0.39926  ,\n",
              "        0.036634 , -0.35431  , -0.42795  ,  0.46444  ,  0.25586  ,\n",
              "        0.68257  , -0.20821  ,  0.38433  ,  0.055773 , -0.2539   ,\n",
              "       -0.20804  ,  0.52522  , -0.11399  , -0.3253   , -0.44104  ,\n",
              "        0.17528  ,  0.62255  ,  0.50237  , -0.7607   , -0.071786 ,\n",
              "        0.0080131, -0.13286  ,  0.50097  ,  0.18824  , -0.54722  ,\n",
              "       -0.42664  ,  0.4292   ,  0.14877  , -0.0072514, -0.16484  ,\n",
              "       -0.059798 ,  0.9895   , -0.61738  ,  0.054169 ,  0.48424  ,\n",
              "       -0.35084  , -0.27053  ,  0.37829  ,  0.11503  , -0.39613  ,\n",
              "        0.24266  ,  0.39147  , -0.075256 ,  0.65093  , -0.20822  ,\n",
              "       -0.17456  ,  0.53571  , -0.16537  ,  0.13582  , -0.56016  ,\n",
              "        0.016964 ,  0.1277   ,  0.94071  , -0.22608  , -0.021106 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# check the first record\n",
        "train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQIQSyF9GtSv"
      },
      "source": [
        "### Save the train split in JSONL format.\n",
        "\n",
        "The data must be formatted in JSONL format, which means each embedding dictionary is written as a JSON string on its own line.\n",
        "\n",
        "Additionally, to demonstrate the filtering functionality, the `restricts` key is set such that each embedding has a different `class`, `even` or `odd`. These are used during the later matching step to filter for results.\n",
        "For additional information of filtering, see [Filter vector matches](https://cloud.google.com/vertex-ai/docs/vector-search/filtering)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "57fe2ce4b50f"
      },
      "outputs": [],
      "source": [
        "with open(\"glove100.json\", \"w\") as f:\n",
        "    embeddings_formatted = [\n",
        "        json.dumps(\n",
        "            {\n",
        "                \"id\": str(index),\n",
        "                \"embedding\": [str(value) for value in embedding],\n",
        "                \"restricts\": [\n",
        "                    {\n",
        "                        \"namespace\": \"class\",\n",
        "                        \"allow\": [\"even\" if index % 2 == 0 else \"odd\"],\n",
        "                    }\n",
        "                ],\n",
        "            }\n",
        "        )\n",
        "        + \"\\n\"\n",
        "        for index, embedding in enumerate(train)\n",
        "    ]\n",
        "    f.writelines(embeddings_formatted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuVl8DrWG8NS"
      },
      "source": [
        "Upload the training data to GCS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "3PgsA_vbI8Vg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94734c81-c02d-4dcb-c09e-2648f186f7e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying file://glove100.json [Content-Type=application/json]...\n",
            "/ [0 files][    0.0 B/  1.4 GiB]                                                \r==> NOTE: You are uploading one or more large file(s), which would run\n",
            "significantly faster if you enable parallel composite uploads. This\n",
            "feature can be enabled by editing the\n",
            "\"parallel_composite_upload_threshold\" value in your .boto\n",
            "configuration file. However, note that if you do this large files will\n",
            "be uploaded as `composite objects\n",
            "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
            "means that any user who downloads such objects will need to have a\n",
            "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
            "without a compiled crcmod, computing checksums on composite objects is\n",
            "so slow that gsutil disables downloads of composite objects.\n",
            "\n",
            "| [1 files][  1.4 GiB/  1.4 GiB]   23.0 MiB/s                                   \n",
            "Operation completed over 1 objects/1.4 GiB.                                      \n"
          ]
        }
      ],
      "source": [
        "EMBEDDINGS_INITIAL_URI = f\"{BUCKET_URI}/vector_search/initial/\"\n",
        "! gsutil cp glove100.json {EMBEDDINGS_INITIAL_URI}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mglUPwHpJH98"
      },
      "source": [
        "## Create Indexes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "qiIg9b5zJLi1"
      },
      "outputs": [],
      "source": [
        "# set no.of dimensions for your embeddings\n",
        "DIMENSIONS = 100\n",
        "# set the dispaly name for ann index\n",
        "DISPLAY_NAME = \"glove_100_1\"\n",
        "# set the display name for brute force index\n",
        "DISPLAY_NAME_BRUTE_FORCE = DISPLAY_NAME + \"_brute_force\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhIBCQ7dDSbW"
      },
      "source": [
        "### Create ANN Index (for Production Usage)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svLYiDf0OD2G"
      },
      "source": [
        "Create the ANN index configuration:\n",
        "\n",
        "To learn more about configuring the index, see [Input data format and structure](https://cloud.google.com/vertex-ai/docs/vector-search/setup/format-structure).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "xzY7TpUSJcTV"
      },
      "outputs": [],
      "source": [
        "tree_ah_index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
        "    display_name=DISPLAY_NAME,\n",
        "    contents_delta_uri=EMBEDDINGS_INITIAL_URI,\n",
        "    dimensions=DIMENSIONS,\n",
        "    approximate_neighbors_count=150,\n",
        "    distance_measure_type=\"DOT_PRODUCT_DISTANCE\",\n",
        "    leaf_node_embedding_count=500,\n",
        "    leaf_nodes_to_search_percent=7,\n",
        "    description=\"Glove 100 ANN index\",\n",
        "    labels={\"label_name\": \"label_value\"},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "17jrQi501QyX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5afb252e-7400-45d7-fc13-b5e4e86a1995"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'projects/249093867948/locations/us-central1/indexes/7028555512790646784'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "INDEX_RESOURCE_NAME = tree_ah_index.resource_name\n",
        "INDEX_RESOURCE_NAME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f1a9fbecabb"
      },
      "source": [
        "Using the resource name, you can retrieve an existing Vector Search Index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "1ddb70647d98"
      },
      "outputs": [],
      "source": [
        "tree_ah_index = aiplatform.MatchingEngineIndex(index_name=INDEX_RESOURCE_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSsqZuyoA1SG"
      },
      "source": [
        "### Create Brute Force Index (for Ground Truth)\n",
        "\n",
        "The brute force index uses a naive brute force method to find the nearest neighbors. This method isn't fast or efficient. Hence, brute force indices are not recommended for production usage. They are to be used to find the \"ground truth\" set of neighbors so that the \"ground truth\" set can be used to measure recall of the indices being tuned for production usage. To ensure an \"apples to apples\" comparison, the `distanceMeasureType` and `dimensions` of the brute force index should match those of the production indices being tuned.\n",
        "\n",
        "Create the brute force index configuration:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "DXnBLqjXBsv8"
      },
      "outputs": [],
      "source": [
        "brute_force_index = aiplatform.MatchingEngineIndex.create_brute_force_index(\n",
        "    display_name=DISPLAY_NAME_BRUTE_FORCE,\n",
        "    contents_delta_uri=EMBEDDINGS_INITIAL_URI,\n",
        "    dimensions=DIMENSIONS,\n",
        "    distance_measure_type=\"DOT_PRODUCT_DISTANCE\",\n",
        "    description=\"Glove 100 index (brute force)\",\n",
        "    labels={\"label_name\": \"label_value\"},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "_oD5SieYJbbW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7b405ed9-d88a-440c-ed70-cbc91fb2d5a5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'projects/249093867948/locations/us-central1/indexes/7031933212511174656'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "INDEX_BRUTE_FORCE_RESOURCE_NAME = brute_force_index.resource_name\n",
        "INDEX_BRUTE_FORCE_RESOURCE_NAME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "865fcad494d7"
      },
      "outputs": [],
      "source": [
        "brute_force_index = aiplatform.MatchingEngineIndex(\n",
        "    index_name=INDEX_BRUTE_FORCE_RESOURCE_NAME\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omlgEZ-sGoM5"
      },
      "source": [
        "## Update Indexes\n",
        "\n",
        "Create an incremental data file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "DDAvm_mj_BVs"
      },
      "outputs": [],
      "source": [
        "with open(\"glove100_incremental.json\", \"w\") as f:\n",
        "    index = 0\n",
        "    f.write(\n",
        "        json.dumps(\n",
        "            {\n",
        "                \"id\": str(index),\n",
        "                \"embedding\": [str(0) for _ in train[index]],\n",
        "                \"restricts\": [\n",
        "                    {\n",
        "                        \"namespace\": \"class\",\n",
        "                        \"allow\": [\"even\" if index % 2 == 0 else \"odd\"],\n",
        "                    }\n",
        "                ],\n",
        "            }\n",
        "        )\n",
        "        + \"\\n\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZU7TU7C7GoM6"
      },
      "source": [
        "Copy the incremental data file to a new subdirectory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "RLWcDvNLGoM6"
      },
      "outputs": [],
      "source": [
        "EMBEDDINGS_UPDATE_URI = f\"{BUCKET_URI}/vector-search/incremental/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "FgpEDX0oGoM6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b2388b5-ed09-43bd-c8f9-ece0d1040c08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying file://glove100_incremental.json [Content-Type=application/json]...\n",
            "\\\n",
            "Operation completed over 1 objects/585.0 B.                                      \n"
          ]
        }
      ],
      "source": [
        "! gsutil cp glove100_incremental.json {EMBEDDINGS_UPDATE_URI}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiXtF_x0GoM6"
      },
      "source": [
        "Create update index request.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "tvedBONtGoM6"
      },
      "outputs": [],
      "source": [
        "tree_ah_index = tree_ah_index.update_embeddings(\n",
        "    contents_delta_uri=EMBEDDINGS_UPDATE_URI,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "HKPDojFpGoM6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "75643e3b-9bd9-4189-df1e-df087fe3b347"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'projects/249093867948/locations/us-central1/indexes/7028555512790646784'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "INDEX_RESOURCE_NAME = tree_ah_index.resource_name\n",
        "INDEX_RESOURCE_NAME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qV2xjAnDDObD"
      },
      "source": [
        "## Create an IndexEndpoint in your VPC Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "BpZQoJyxDlbO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7e8c6990-a713-4661-9afa-3dd385a6fdeb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'projects/249093867948/global/networks/colab-research-vpc'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# Retrieve the project number\n",
        "PROJECT_NUMBER = !gcloud projects list --filter=\"PROJECT_ID:'{PROJECT_ID}'\" --format='value(PROJECT_NUMBER)'\n",
        "PROJECT_NUMBER = PROJECT_NUMBER[0]\n",
        "# Get the full network resource name\n",
        "VPC_NETWORK_FULL = \"projects/{}/global/networks/{}\".format(PROJECT_NUMBER, VPC_NETWORK)\n",
        "VPC_NETWORK_FULL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "QuARXzJVGyQX"
      },
      "outputs": [],
      "source": [
        "# Create your IndexEndpoint\n",
        "my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
        "    display_name=\"index_endpoint_for_demo\",\n",
        "    description=\"index endpoint description\",\n",
        "    network=VPC_NETWORK_FULL,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "PJ3bcZqi-cfM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f2ed7592-d834-4d10-8de5-88666a0a2271"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'projects/249093867948/locations/us-central1/indexEndpoints/6750423051428429824'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "INDEX_ENDPOINT_NAME = my_index_endpoint.resource_name\n",
        "INDEX_ENDPOINT_NAME"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "np2cgVuuIe9k"
      },
      "source": [
        "## Deploy Indexes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ew1UgcIIiJG"
      },
      "source": [
        "### Deploy ANN Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "nLOYTGygIlMK"
      },
      "outputs": [],
      "source": [
        "# Set an id for your ann index deployment\n",
        "DEPLOYED_INDEX_ID = \"tree_ah_glove_deployed_unique\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "_uK4WOgqN1NG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac4ce886-ccbe-4035-d5ea-60399558efde"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[id: \"tree_ah_glove_deployed_unique\"\n",
              "index: \"projects/249093867948/locations/us-central1/indexes/7028555512790646784\"\n",
              "create_time {\n",
              "  seconds: 1758445602\n",
              "  nanos: 975917000\n",
              "}\n",
              "private_endpoints {\n",
              "  match_grpc_address: \"10.117.0.14\"\n",
              "}\n",
              "index_sync_time {\n",
              "  seconds: 1758445602\n",
              "  nanos: 975917000\n",
              "}\n",
              "automatic_resources {\n",
              "  min_replica_count: 2\n",
              "  max_replica_count: 2\n",
              "}\n",
              "deployment_group: \"default\"\n",
              "]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "# Deploy your ann index\n",
        "my_index_endpoint = my_index_endpoint.deploy_index(\n",
        "    index=tree_ah_index, deployed_index_id=DEPLOYED_INDEX_ID\n",
        ")\n",
        "\n",
        "my_index_endpoint.deployed_indexes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNZnXmO5AhDO"
      },
      "source": [
        "### Deploy Brute Force Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "3p9e4828AkSv"
      },
      "outputs": [],
      "source": [
        "# Set an id for your brute force index deployment\n",
        "DEPLOYED_BRUTE_FORCE_INDEX_ID = \"glove_brute_force_deployed_unique\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "-2kgd01SA4rk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0578443-8aaf-4937-9a8f-dc674c06f205"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[id: \"tree_ah_glove_deployed_unique\"\n",
              "index: \"projects/249093867948/locations/us-central1/indexes/7028555512790646784\"\n",
              "create_time {\n",
              "  seconds: 1758445602\n",
              "  nanos: 975917000\n",
              "}\n",
              "private_endpoints {\n",
              "  match_grpc_address: \"10.117.0.14\"\n",
              "}\n",
              "index_sync_time {\n",
              "  seconds: 1758447328\n",
              "  nanos: 242064000\n",
              "}\n",
              "automatic_resources {\n",
              "  min_replica_count: 2\n",
              "  max_replica_count: 2\n",
              "}\n",
              "deployment_group: \"default\"\n",
              ", id: \"glove_brute_force_deployed_unique\"\n",
              "index: \"projects/249093867948/locations/us-central1/indexes/7031933212511174656\"\n",
              "create_time {\n",
              "  seconds: 1758447249\n",
              "  nanos: 99946000\n",
              "}\n",
              "private_endpoints {\n",
              "  match_grpc_address: \"10.117.0.14\"\n",
              "}\n",
              "index_sync_time {\n",
              "  seconds: 1758447493\n",
              "  nanos: 504964000\n",
              "}\n",
              "automatic_resources {\n",
              "  min_replica_count: 2\n",
              "  max_replica_count: 2\n",
              "}\n",
              "deployment_group: \"default\"\n",
              "]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "# Deploy your brute force index\n",
        "my_index_endpoint = my_index_endpoint.deploy_index(\n",
        "    index=brute_force_index, deployed_index_id=DEPLOYED_BRUTE_FORCE_INDEX_ID\n",
        ")\n",
        "\n",
        "my_index_endpoint.deployed_indexes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LCGvBNvBd8D"
      },
      "source": [
        "## Create online queries\n",
        "\n",
        "After you've built your indexes, you may query against the deployed index through the online querying gRPC API (Match service) within the virtual machine instances from the same region (for example, 'us-central1' in this tutorial).\n",
        "\n",
        "The `filter` parameter is an optional way to filter for a subset of embeddings. In this case, only embeddings that have the `class` set as `even` are returned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "A3KYVw5HB-4v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "23c237a5-2451-4241-8743-57f67bd2c225"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "_InactiveRpcError",
          "evalue": "<_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"failed to connect to all addresses; last error: UNKNOWN: ipv4:10.117.0.14:10000: Failed to connect to remote host: Timeout occurred: FD Shutdown\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {grpc_status:14, grpc_message:\"failed to connect to all addresses; last error: UNKNOWN: ipv4:10.117.0.14:10000: Failed to connect to remote host: Timeout occurred: FD Shutdown\"}\"\n>",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1539781835.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Use match service with a test query\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m response = my_index_endpoint.match(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdeployed_index_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEPLOYED_INDEX_ID\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mqueries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnum_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_NEIGHBOURS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/aiplatform/matching_engine/matching_engine_index_endpoint.py\u001b[0m in \u001b[0;36mmatch\u001b[0;34m(self, deployed_index_id, queries, num_neighbors, filter, per_crowding_attribute_num_neighbors, approx_num_neighbors, fraction_leaf_nodes_to_search_override, low_level_batch_size, numeric_filter, signed_jwt, psc_network)\u001b[0m\n\u001b[1;32m   2194\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msigned_jwt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2195\u001b[0m             \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"authorization\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Bearer: {signed_jwt}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2196\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchMatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2198\u001b[0m         \u001b[0;31m# Wrap the results in MatchNeighbor objects and return\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_for_ready\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         )\n\u001b[0;32m-> 1181\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_end_unary_response_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m     def with_call(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m   1007\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1009\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_InactiveRpcError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pytype: disable=not-instantiable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.UNAVAILABLE\n\tdetails = \"failed to connect to all addresses; last error: UNKNOWN: ipv4:10.117.0.14:10000: Failed to connect to remote host: Timeout occurred: FD Shutdown\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {grpc_status:14, grpc_message:\"failed to connect to all addresses; last error: UNKNOWN: ipv4:10.117.0.14:10000: Failed to connect to remote host: Timeout occurred: FD Shutdown\"}\"\n>"
          ]
        }
      ],
      "source": [
        "# Use match service with a test query\n",
        "response = my_index_endpoint.match(\n",
        "    deployed_index_id=DEPLOYED_INDEX_ID,\n",
        "    queries=test[:1].tolist(),\n",
        "    num_neighbors=NUM_NEIGHBOURS,\n",
        "    filter=[Namespace(\"class\", [\"even\"])],\n",
        ")\n",
        "\n",
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeUZO3bAGoM-"
      },
      "source": [
        "### Compute recall\n",
        "\n",
        "Use the deployed brute force Index as the ground truth to calculate the recall of ANN Index. You can run multiple queries in a single match call."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9dNIbkEGoM-"
      },
      "outputs": [],
      "source": [
        "# Retrieve nearest neighbors for both the tree-AH index and the brute force index\n",
        "tree_ah_response_test = my_index_endpoint.match(\n",
        "    deployed_index_id=DEPLOYED_INDEX_ID,\n",
        "    queries=test[:].tolist(),\n",
        "    num_neighbors=NUM_NEIGHBOURS,\n",
        ")\n",
        "brute_force_response_test = my_index_endpoint.match(\n",
        "    deployed_index_id=DEPLOYED_BRUTE_FORCE_INDEX_ID,\n",
        "    queries=test[:].tolist(),\n",
        "    num_neighbors=NUM_NEIGHBOURS,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-eMF05UGoM-"
      },
      "outputs": [],
      "source": [
        "# Calculate recall by determining how many neighbors were correctly retrieved as compared to the brute force option.\n",
        "recalled_neighbors = 0\n",
        "for tree_ah_neighbors, brute_force_neighbors in zip(\n",
        "    tree_ah_response_test, brute_force_response_test\n",
        "):\n",
        "    tree_ah_neighbor_ids = [neighbor.id for neighbor in tree_ah_neighbors]\n",
        "    brute_force_neighbor_ids = [neighbor.id for neighbor in brute_force_neighbors]\n",
        "\n",
        "    recalled_neighbors += len(\n",
        "        set(tree_ah_neighbor_ids).intersection(brute_force_neighbor_ids)\n",
        "    )\n",
        "\n",
        "recall = recalled_neighbors / len(\n",
        "    [neighbor for neighbors in brute_force_response_test for neighbor in neighbors]\n",
        ")\n",
        "\n",
        "print(\"Recall: {}\".format(recall))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpV-iwP9qw9c"
      },
      "source": [
        "## Cleaning up\n",
        "\n",
        "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud\n",
        "project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
        "You can also manually delete resources that you created by running the following code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "sx_vKniMq9ZX"
      },
      "outputs": [],
      "source": [
        "delete_bucket = False\n",
        "\n",
        "# Force undeployment of indexes and delete endpoint\n",
        "my_index_endpoint.delete(force=True)\n",
        "\n",
        "# Delete indexes\n",
        "tree_ah_index.delete()\n",
        "brute_force_index.delete()\n",
        "\n",
        "if delete_bucket:\n",
        "    ! gsutil rm -rf {BUCKET_URI}"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "sdk_vector_search_for_indexing.ipynb",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}